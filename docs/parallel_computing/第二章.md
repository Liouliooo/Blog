# 第二章-术语

## CPU

当代的CPU由一个或多个内核组成——一个具有自己指令流的独立执行单元。带有CPU的内核可以组织成一个或多个插槽。

## NODE

一个独立的“计算机盒子”，通常由多个 CPUs/processors/cores、内存、网络结构等。多个节点通过网络连接到一块组成一台超级计算机。

## TASK

计算工作中逻辑上离散的单元。task 通常是由处理器执行的程序或者类似程序的指令集。并行程序由多个处理器上运行的多个任务组成。

## PIPELINE

- 将一个任务分成一系列的步骤由不同的处理单元处理，很像集成流水线
- 一种并行计算方法

## SHARED MEMORY

- 计算机体系结构角度看待，是所有处理器都可以直接访存的公告物理内存
- 编程角度看待，并行任务都拥有的相同的 “picture”，并且可以直接寻址访存的逻辑内存，而不管物理内存的实际位置

## SYMMETRIC MULTI-PROCESSOR (SMP)

共享内存硬件体系结构，其中多处理器共享一个地址空间，并对所有资源（内存、磁盘等）具有同等访问权。

## DISTRIBUTED MEMORY

- 硬件中指的是基于网络的物理内存访存
- 编程模型中，任务只能在逻辑上“查看”本地机器内存，并且必须使用通信来访存其他机器上的内存

## COMMUNICATIONS

并行任务通常需要交换数据。有几种实现方法：
- shared memory
- network

这就是通信。

## SYNCHRONIZATION

实时协调并行任务，通常与通信有关。 </br>
同步通常涉及至少一个任务的等待，因此会导致并行程序的执行时间增加。

## COMPUTATIONAL GRANULARITY

在并行计算中，粒度是计算与通信比例的定量或定性度量：
- 粗粒度（Coarse）：在通信之间完成相对大量的计算工作
- 细粒度（Fine）：在通信之间完成相对较少的计算工作

## OBSERVED SPEEDUP

加速比定义为:
```
 wall-clock time of serial execution
---------------------------------------
 wall-clock time of parallel execution
```
加速比（speedup）是衡量并行程序性能最简单、最常用的指标之一。

## PARALLEL OVERHEAD

并行任务所特有的执行时间，不是其他工作的时间。并行开销的因素由：
- 任务启动时间
- 同步
- 数据通信
- 并行语言、库、操作系统等造成的软件开销
- 任务终止时间

## MASSIVELY PARALLEL

包含许多处理单元的并行硬件系统。“many”的含义在不断的增加，目前最大的并行计算机由数十万到数百万的处理单元组成。

## EMBARRASSINGLY (IDEALY) PARALLEL

指的是同时解决许多相似但独立的任务，任务之间只需要少量的或者不需要协调。

## SCALABILITY

指并行系统（硬件和/或软件）通过增加更多的资源来提升加速比的能力。促进 scalability 的因素包括：
- 硬件，特别是内存与cpu的带宽和通信网络
- 应用算法
- 并行开销相关
- 自己程序的特性

## 参考资料

[Introduction parallel computing tutorial](https://hpc.llnl.gov/training/tutorials/introduction-parallel-computing-tutorial)
