# 第四章(上)-并行程序性能分析

<font color=red size=6>渐入佳境</font>

## 加速比 & 效率

加速比的定义为：$S(p) = \frac{T_s}{T_p}$ </br>

$T_s$：最优串行算法的执行时间 </br>

$T_p$：使用 p 个处理器的执行时间 </br>

<div align="center">
  <img src="/images/parallel_computing/4/speedup.JPG" width="350" alt="串行"/>
</div>

### 加速比

- Linear speedup: $S(p) = p$
  + 理论上理想的加速比

- Superlinear speedup: $S(p) > p$
  + 偶尔在实践中发生
  + 额外的硬件资源（例如：memory）
  + 软件或硬件的优化（例如：caching）

- Maximum Speedup
  + 达到理想的最大加速比 $S(p) = p$ 很困难
    - 程序不是每个不都能并行化（导致处理器**空闲**）
    - 在并行计算中需要**额外**的计算量（例如：同步的开销）
    - 多个程序之间需要**通信**（通常是主要因素）
  + 使 $f$ 表示程序中**无法并行**的部分
    - $S(p) = \frac{t_s}{ft_s + (1-f)t_s/p}$
    - 假如处理器的数量趋向于无限大：$S(p)_{p \to \infty} = \frac{p}{1+(p-1)f} = \frac{1}{f}$

<div align="center">
  <img src="/images/parallel_computing/4/speedup_sp.JPG" alt="串行"/>
</div>

### 系统效率

System efficiency: $E(p) = \frac{T_s}{T_p \times p} = \frac{S(p)}{p} \times 100\%$

## 强扩展性 & 弱扩展性

### 强扩展性 strong scalability

- 针对一个问题，<font color=red>**负载**</font>不变，处理器个数增加
- 旨在更快的解决一个问题
- 如果加速比等于处理器个数，就能实现<font color=red>**线性**</font>规模的增加

<div align="center">
  <img src="/images/parallel_computing/4/strong_scalability.JPG" alt="串行"/>
</div>

### 弱扩展性 weak scalability

- 分配给每个处理器的负载保持固定，增加处理器的数量能够解决**更大规模**的问题
- 旨在用相同的时间解决更大规模的问题
- 运行时间不变，工作能够不断增加，可实现<font color=red>**线性**</font>规模的增长

<div align="center">
  <img src="/images/parallel_computing/4/weak_scalability.JPG" alt="串行"/>
</div>

### 两者对比

|Strong scaling | Weak scaling |
|-|-|
| 线性规模难以实现，因为随着问题规模增加，**通信开销**也会同比例增加 | 线性规模增加容易实现，因为不管使用多少进程，**通信开销**相对固定</br>通信使用 **nearest-neighbor communication patterns** |

## 时间复杂度 & Cost optimality

本节的**时间复杂度**和**代价优化**不仅考虑了<font color=red>**并行算法**</font>的设计，还考虑了并行部分的<font color=red>**通信**</font>。

### Time Complexity Analysis

- $T_p = T_{comp} + T_{comm}$
  + $T_p$: 并行**算法**的执行时间
  + $T_{comp}$: **计算**部分的消耗
  + $T_{comm}$: **同步**部分的消耗

- $T_{comm} = q(T_{startup} + nT_{data})$
  + $T_{startup}$: **消息延迟**（假设固定）
  + $T_{data}$: 一条数据的**传输时间**
  + $n$: 在一个消息中的数据的**条数**
  + $q$: **消息**的数量

<div align="center">
  <img src="/images/parallel_computing/4/time_comm.jpg" width=400 alt="串行"/>
</div>

---

累加 $N$ 个数字的并行算法设计：

★ **算法1**

用<font color=red>**2个**</font>计算机来并行计算：

- step-1. 电脑1把 $n/2$ 个数发送给 电脑2
- step-2. 两台电脑同时加 $n/2$ 个数
- step-3. 电脑2把部分和发送回电脑1
- step-4. 电脑1把两个部分和加起来得到最终结果

复杂度分析：

- Computation: (step-2 和 step-4)
  + $T_{comp} = n/2 + 1 = O(n)$
- Communication: (step-1 和 step-3)
  + $T_{comm} = (T_{startup} + n/2 \times T_{data}) + (T_{startup} + T_{data}) = 2T_{startup} + (n/2 + 1)T_{data} = O(n)$
- **总体**的时间复杂度：$T_p = T_{comp} + T_{comm}=$ <font color=red>$O(n)$</font>

---

★ **算法2**

用<font color=red>**m个**</font>处理器来并行计算：

（1）把 n 个数字平均的分给 m 个处理器 </br>
（2）m 个处理器同时相加 n/m 个数字 </br>
（3） 把 m 个部分和返回到一个处理器，相加得到最终结果 </br>

并行处理流程：

- Phase1: 把 n 个数字发送给 m 个 slaves
  + $t_{comm1} = m(t_{startup} + (n/m)t_{data})$
- Phase2: 累加部分和
  + $t_{comp1} = n/m - 1$
- Phase3: 把结果发送给 master
  + $t_{comm2} = m(t_{startup} + t_{data})$
- Phase4: 计算最终结果
  + $t_{comp2} = m - 1$
- Overall: 时间复杂度
  + $t_p = 2mt_{startup} + (n + m)t_{data} + m + \frac{n}{m} - 2$

由上述两个算法例子可知：</br>
◇ 处理器个数少，通信开销少，计算的时间复杂度更高 </br>
◇ 处理器个数多，通信开销大，计算的时间复杂度更少 </br>

所以设计并行算法需要在 **computation** 和 **communication** 之间做<font color=red>**权衡**</font>。

---

### Cost Optimal Algorithm

- 定义
  + 解决问题的<font color=red>**代价**</font>随着在单个处理器上的执行时间成正比例关系
  + $O(T_p) \times N = O(T_s)$
    - $O(T_s)$: 执行**串行**算法的时间复杂度
    - $O(T_p)$: 执行**并行**算法的时间复杂度
- 例子
  + Sequential algorithm: $O(N\log{N})$
  + Parallel algorithm 1: uses $N$ processor with $O(\log{N})$
  + Parallel algorithm 2: uses $N^2$ processor with $O(1)$

## 参考资料

[Introduction parallel computing tutorial](https://hpc.llnl.gov/training/tutorials/introduction-parallel-computing-tutorial)

台湾新竹清华大学 [平行程式](https://ocw.nthu.edu.tw/ocw/index.php?page=course&cid=231)
